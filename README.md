# Offensive-Text-Identification
### The main idea is to implement and compare the performances of the ML models that can be used to identify offensive texts and find the most suitable model to implement for a web application.

### Dataset used: *Offensive Language Identification Dataset (OLID)*
### Tools used:
* Python
* Flask 
* HTML and CSS
* JavaScript<br>
### Models implemented:
1. Naive Bayes Classification
   - Accuracy: **71%**
   - Excecution time: **0.01s**
2. Long Short-term Memory (LSTM)
   - Accuracy: **75%**
   - Execution time: **0.28s**
### Model used for the Web App: *Naive Bayes*
## Outputs:
![image](https://user-images.githubusercontent.com/67289887/143850988-e4f451b0-7922-474b-a718-6fa74509ef29.png)
![image](https://user-images.githubusercontent.com/67289887/143851041-996adb38-74c6-4a97-9c99-464af6c538bd.png)

For further explanation about the project, you can read our research paper [here](https://www.irjet.net/archives/V8/i11/IRJET-V8I11251.pdf)

